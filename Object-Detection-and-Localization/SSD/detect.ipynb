{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"detect.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"VUZsovIS3c1r","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHPrZANC3c9n","colab_type":"code","colab":{}},"source":["# This is all code for authentication of drive by the google colab and then importing drive and then importing our module from it..\n","\n","!pip install import-ipynb\n","import import_ipynb\n","# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","\n","drive = GoogleDrive(gauth)\n"," # create Object of your file to be imported by keeping its id which can easily get from its sharable link after this give it any name u want like here i gave it as module\n","your_module = drive.CreateFile({'id':'12oazlewJ-tzDirjptZ6ZmPgbi7Dzhwa6'})\n","your_module.GetContentFile('util_module.ipynb')\n","from util_module import *\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRuygvvgGq3L","colab_type":"code","colab":{}},"source":["from torchvision import transforms\n","#from utils import *\n","from PIL import Image, ImageDraw, ImageFont\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTdnGKdxGz1b","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load model checkpoint\n","#checkpoint = 'BEST_checkpoint_ssd300.pth.tar'\n","checkpoint = r'/content/drive/My Drive/Computer_Vision_project/BEST_checkpoint_ssd300.pth.tar'\n","checkpoint = torch.load(checkpoint)\n","start_epoch = checkpoint['epoch'] + 1\n","best_loss = checkpoint['best_loss']\n","print('\\nLoaded checkpoint from epoch %d. Best loss so far is %.3f.\\n' % (start_epoch, best_loss))\n","model = checkpoint['model']\n","model = model.to(device)\n","model.eval()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEFJxuqWGz7Z","colab_type":"code","colab":{}},"source":["# Transforms\n","resize = transforms.Resize((300, 300))\n","to_tensor = transforms.ToTensor()\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N5x95h9UG0Dq","colab_type":"code","colab":{}},"source":["def detect(original_image, min_score, max_overlap, top_k, suppress=None):\n","    \"\"\"\n","    Detect objects in an image with a trained SSD300, and visualize the results.\n","\n","    :param original_image: image, a PIL Image\n","    :param min_score: minimum threshold for a detected box to be considered a match for a certain class\n","    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via Non-Maximum Suppression (NMS)\n","    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n","    :param suppress: classes that you know for sure cannot be in the image or you do not want in the image, a list\n","    :return: annotated image, a PIL Image\n","    \"\"\"\n","\n","    # Transform\n","    image = normalize(to_tensor(resize(original_image)))\n","\n","    # Move to default device\n","    image = image.to(device)\n","\n","    # Forward prop.\n","    predicted_locs, predicted_scores = model(image.unsqueeze(0))\n","\n","    # Detect objects in SSD output\n","    det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score,\n","                                                             max_overlap=max_overlap, top_k=top_k)\n","\n","    # Move detections to the CPU\n","    det_boxes = det_boxes[0].to('cpu')\n","\n","    # Transform to original image dimensions\n","    original_dims = torch.FloatTensor(\n","        [original_image.width, original_image.height, original_image.width, original_image.height]).unsqueeze(0)\n","    det_boxes = det_boxes * original_dims\n","\n","    # Decode class integer labels\n","    det_labels = [rev_label_map[l] for l in det_labels[0].to('cpu').tolist()]\n","\n","    # If no objects found, the detected labels will be set to ['0.'], i.e. ['background'] in SSD300.detect_objects() in model.py\n","    if det_labels == ['background']:\n","        # Just return original image\n","        return original_image\n","\n","    # Annotate\n","    annotated_image = original_image\n","    draw = ImageDraw.Draw(annotated_image)\n","    font = ImageFont.truetype(\"./calibril.ttf\", 15)\n","\n","    # Suppress specific classes, if needed\n","    for i in range(det_boxes.size(0)):\n","        if suppress is not None:\n","            if det_labels[i] in suppress:\n","                continue\n","\n","        # Boxes\n","        box_location = det_boxes[i].tolist()\n","        draw.rectangle(xy=box_location, outline=label_color_map[det_labels[i]])\n","        draw.rectangle(xy=[l + 1. for l in box_location], outline=label_color_map[\n","            det_labels[i]])  # a second rectangle at an offset of 1 pixel to increase line thickness\n","        # draw.rectangle(xy=[l + 2. for l in box_location], outline=label_color_map[\n","        #     det_labels[i]])  # a third rectangle at an offset of 1 pixel to increase line thickness\n","        # draw.rectangle(xy=[l + 3. for l in box_location], outline=label_color_map[\n","        #     det_labels[i]])  # a fourth rectangle at an offset of 1 pixel to increase line thickness\n","\n","        # Text\n","        text_size = font.getsize(det_labels[i].upper())\n","        text_location = [box_location[0] + 2., box_location[1] - text_size[1]]\n","        textbox_location = [box_location[0], box_location[1] - text_size[1], box_location[0] + text_size[0] + 4.,\n","                            box_location[1]]\n","        draw.rectangle(xy=textbox_location, fill=label_color_map[det_labels[i]])\n","        draw.text(xy=text_location, text=det_labels[i].upper(), fill='white',\n","                  font=font)\n","    del draw\n","\n","    return annotated_image\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2qsvorv5G0HV","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    #img_path = '/media/ssd/ssd data/VOC2007/JPEGImages/000001.jpg'\n","    img_path = r'/content/drive/My Drive/Computer_Vision_project/VOC_2007/VOC_test_2007/JPEGImages/000001.jpg'\n","    original_image = Image.open(img_path, mode='r')\n","    original_image = original_image.convert('RGB')\n","    detect(original_image, min_score=0.2, max_overlap=0.5, top_k=200).show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4QvWmXtGz51","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}